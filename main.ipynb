{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c995f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mtcnn opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c314ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from mtcnn import MTCNN\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334e9cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "detector = MTCNN()\n",
    "BLUR_THRESHOLD = 80   # increase = strict filtering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b1b466",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_blurry(image, thresh=BLUR_THRESHOLD):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    val = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "    return val < thresh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26540102",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_image_generator(directory, batch_size=BATCH_SIZE):\n",
    "    class_names = sorted(os.listdir(directory))\n",
    "    class_to_index = {name: idx for idx, name in enumerate(class_names)}\n",
    "    \n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    while True:\n",
    "        for class_name in class_names:\n",
    "            class_path = os.path.join(directory, class_name)\n",
    "            if not os.path.isdir(class_path):\n",
    "                continue\n",
    "\n",
    "            for file in os.listdir(class_path):\n",
    "                path = os.path.join(class_path, file)\n",
    "\n",
    "                # Load image\n",
    "                img = cv2.imread(path)\n",
    "                if img is None:\n",
    "                    continue  # corrupted image\n",
    "\n",
    "                if is_blurry(img):\n",
    "                    continue  # skip blurry\n",
    "\n",
    "                rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                faces = detector.detect_faces(rgb)\n",
    "\n",
    "                if len(faces) != 1:\n",
    "                    continue  # skip multi-face or no-face\n",
    "\n",
    "                # Face box\n",
    "                x, y, w, h = faces[0]['box']\n",
    "                face_crop = rgb[y:y+h, x:x+w]\n",
    "\n",
    "                # Resize for model\n",
    "                face_crop = cv2.resize(face_crop, IMG_SIZE)\n",
    "                face_crop = face_crop / 255.0\n",
    "\n",
    "                images.append(face_crop)\n",
    "                labels.append(class_to_index[class_name])\n",
    "\n",
    "                # Yield batch\n",
    "                if len(images) == batch_size:\n",
    "                    yield np.array(images), tf.keras.utils.to_categorical(labels, num_classes=len(class_names))\n",
    "                    images, labels = [], []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc1e2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = sorted([d for d in os.listdir(\"images\") if os.path.isdir(os.path.join(\"images\", d))])\n",
    "num_classes = len(class_names)\n",
    "print(\"Classes:\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0584d776",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = clean_image_generator(\"images\", batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7642165d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = tf.keras.applications.MobileNetV2(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "base.trainable = False\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    base,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f90542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 8s/step - accuracy: 0.0167 - loss: 4.6070\n",
      "Epoch 2/15\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 8s/step - accuracy: 0.1250 - loss: 2.7244\n",
      "Epoch 3/15\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 9s/step - accuracy: 0.2146 - loss: 2.4819\n",
      "Epoch 4/15\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 17s/step - accuracy: 0.2500 - loss: 2.3714\n",
      "Epoch 5/15\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 16s/step - accuracy: 0.2333 - loss: 2.3049\n",
      "Epoch 6/15\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 8s/step - accuracy: 0.3354 - loss: 2.1247\n",
      "Epoch 7/15\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 8s/step - accuracy: 0.4042 - loss: 1.9333\n",
      "Epoch 8/15\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 19s/step - accuracy: 0.5104 - loss: 1.7340\n",
      "Epoch 9/15\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 19s/step - accuracy: 0.5333 - loss: 1.6690\n",
      "Epoch 10/15\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 13s/step - accuracy: 0.5583 - loss: 1.5693\n",
      "Epoch 11/15\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 10s/step - accuracy: 0.6167 - loss: 1.4069\n",
      "Epoch 12/15\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 17s/step - accuracy: 0.6521 - loss: 1.3069\n",
      "Epoch 13/15\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 7s/step - accuracy: 0.7083 - loss: 1.1689\n",
      "Epoch 14/15\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 9s/step - accuracy: 0.7750 - loss: 1.0361\n",
      "Epoch 15/15\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 8s/step - accuracy: 0.7688 - loss: 0.9806\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x24cda9f9e80>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=15,   # change based on data size\n",
    "    epochs=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e73509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct way to save model\n",
    "model.save(\"cricknet_model.keras\")\n",
    "\n",
    "# save class dictionary\n",
    "class_dict = {\n",
    "    'bhuvneshwar_kumar': 0,\n",
    "    'dinesh_karthik': 1,\n",
    "    'hardik_pandya': 2,\n",
    "    'jasprit_bumrah': 3,\n",
    "    'k._l._rahul': 4,\n",
    "    'kedar_jadhav': 5,\n",
    "    'kuldeep_yadav': 6,\n",
    "    'mohammed_shami': 7,\n",
    "    'ms_dhoni': 8,\n",
    "    'ravindra_jadeja': 9,\n",
    "    'rohit_sharma': 10,\n",
    "    'shikhar_dhawan': 11,\n",
    "    'vijay_shankar': 12,\n",
    "    'virat_kohli': 13,\n",
    "    'yuzvendra_chahal': 14\n",
    "}\n",
    "\n",
    "import json\n",
    "with open(\"class_dictionary.json\", \"w\") as f:\n",
    "    json.dump(class_dict, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
